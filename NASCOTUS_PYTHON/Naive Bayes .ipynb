{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68de59a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8120862861147886\n"
     ]
    }
   ],
   "source": [
    "# NAIVE BAYESSSSSSSS\n",
    "\n",
    "# standard\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "data = pd.read_csv('NASCOTUS_fixed.csv')\n",
    "\n",
    "# splitttering\n",
    "X = data.drop(['justicesDecision', 'presAffiliation'], axis=1)\n",
    "y = data['justicesDecision']\n",
    "\n",
    "\n",
    "# 1 hot encoddeing\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "X_encoded = pd.DataFrame(encoder.fit_transform(X[categorical_cols]))\n",
    "X_encoded.columns = encoder.get_feature_names_out(categorical_cols)\n",
    "\n",
    "\n",
    "X = X.drop(categorical_cols, axis=1)\n",
    "X = pd.concat([X, X_encoded], axis=1)\n",
    "\n",
    "\n",
    "# train _ test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# yas \n",
    "class_counts = y_train.value_counts()\n",
    "class_prior = class_counts / len(y_train)\n",
    "\n",
    "# weights\n",
    "class_weights = [class_prior[0], class_prior[1]]  # this assumes 0 is majority class and 1 is minority\n",
    "# creating and training GNB using class weighting\n",
    "naive_bayes = GaussianNB(priors=class_weights)\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "# predciting\n",
    "predictions = naive_bayes.predict(X_test)\n",
    "\n",
    "# accuracy evaluation\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Test Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "617c6b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.4650728136437972\n"
     ]
    }
   ],
   "source": [
    "# I WAS GETTING AN issue where regardless of what I remove, the accuracy stays the same, so now I'm trying a new approach\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# data loading\n",
    "data = pd.read_csv('NASCOTUS_fixed.csv')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(['justicesDecision'], axis=1)\n",
    "y = data['justicesDecision']\n",
    "\n",
    "# 1 hot encoddeing\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "X_encoded = pd.DataFrame(encoder.fit_transform(X[categorical_cols]))\n",
    "X_encoded.columns = encoder.get_feature_names_out(categorical_cols)\n",
    "\n",
    "\n",
    "X = X.drop(categorical_cols, axis=1)\n",
    "X = pd.concat([X, X_encoded], axis=1)\n",
    "\n",
    "\n",
    "# split train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# applying smote oversampling to the data....\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# train\n",
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "#predicting\n",
    "predictions = naive_bayes.predict(X_test)\n",
    "\n",
    "# ACCURACY\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Test Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "729cda8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lawType: 0.2128854229154169\n",
      "certReason: 0.19700059988002394\n",
      "presAffiliation: 0.04911817636472704\n",
      "lcDispositionDirection: 0.0015116976604678811\n"
     ]
    }
   ],
   "source": [
    "# I am checking for feature improtances\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = np.abs(naive_bayes.theta_[1] - naive_bayes.theta_[0])  # Difference in mean values for each feature\n",
    "\n",
    "# Sort feature importances\n",
    "sorted_indices = np.argsort(feature_importances)[::-1]\n",
    "sorted_features = X_train.columns[sorted_indices]\n",
    "\n",
    "# Print feature importances\n",
    "for feature, importance in zip(sorted_features, feature_importances[sorted_indices]):\n",
    "    print(f\"{feature}: {importance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6c11f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21268221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
